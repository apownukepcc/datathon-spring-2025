{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM7v6SeJ8u+1JLnsJwHui+5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y23HDdx0S8BZ","executionInfo":{"status":"ok","timestamp":1738778902919,"user_tz":420,"elapsed":20776,"user":{"displayName":"Andrew Pownuk","userId":"03168004100943721436"}},"outputId":"9d5f7f2f-ee4e-45bf-c45a-3e117e04c8d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Dataset successfully loaded from GitHub.\n","Datasets generated and saved:\n","- /content/drive/My Drive/SO2TONS_dataset.csv\n","- /content/drive/My Drive/NOXTONS_dataset.csv\n","- /content/drive/My Drive/COTONS_dataset.csv\n"]}],"source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define file paths\n","github_url = \"https://raw.githubusercontent.com/apownukepcc/datathon-spring-2025/main/combined_data.csv\"\n","output_so2tons_file = \"/content/drive/My Drive/SO2TONS_dataset.csv\"\n","output_noxtons_file = \"/content/drive/My Drive/NOXTONS_dataset.csv\"\n","output_cotons_file = \"/content/drive/My Drive/COTONS_dataset.csv\"\n","\n","# Load the dataset from GitHub\n","try:\n","    data = pd.read_csv(github_url)\n","    print(\"Dataset successfully loaded from GitHub.\")\n","except Exception as e:\n","    print(f\"Error loading dataset from GitHub: {e}\")\n","    exit()\n","\n","# Define the emissions parameters\n","emissions_params = ['SO2TONS', 'NOXTONS', 'COTONS']\n","load_param = 'LOADMWBA'\n","\n","# Step 1: Separate emissions and load data\n","emissions_data = data[data['Parameter'].isin(emissions_params)]\n","load_data = data[data['Parameter'] == load_param]\n","\n","# Step 2: Merge emissions and load data based on 'date' and 'Source'\n","merged_data = pd.merge(\n","    emissions_data,\n","    load_data,\n","    on=[\"date\", \"Source\"],\n","    suffixes=(\"_emission\", \"_load\"),\n","    how=\"left\"\n",")\n","\n","# Step 3: Calculate Emissions_Load\n","merged_data[\"Emissions_Load\"] = merged_data[\"Value_emission\"] / merged_data[\"Value_load\"]\n","\n","# Step 4: Add Emissions_Load back to the original dataset\n","data_with_emissions_load = pd.merge(\n","    data,\n","    merged_data[[\"date\", \"Source\", \"Parameter_emission\", \"Emissions_Load\"]],\n","    left_on=[\"date\", \"Source\", \"Parameter\"],\n","    right_on=[\"date\", \"Source\", \"Parameter_emission\"],\n","    how=\"left\"\n",").drop(columns=[\"Parameter_emission\"], errors=\"ignore\")\n","\n","# Step 5: Define a function to filter the dataset for a specific parameter\n","def filter_dataset(data, parameter):\n","    # Filter rows for the specific parameter\n","    parameter_data = data[data['Parameter'] == parameter]\n","    # Remove rows with NaN or zero Emissions_Load\n","    parameter_data = parameter_data.dropna(subset=['Emissions_Load'])\n","    parameter_data = parameter_data[parameter_data['Emissions_Load'] > 0]\n","    return parameter_data\n","\n","# Step 6: Generate datasets for SO2TONS, NOXTONS, and COTONS\n","so2tons_data = filter_dataset(data_with_emissions_load, 'SO2TONS')\n","noxtons_data = filter_dataset(data_with_emissions_load, 'NOXTONS')\n","cotons_data = filter_dataset(data_with_emissions_load, 'COTONS')\n","\n","# Step 7: Save the filtered datasets to separate CSV files\n","so2tons_data.to_csv(output_so2tons_file, index=False)\n","noxtons_data.to_csv(output_noxtons_file, index=False)\n","cotons_data.to_csv(output_cotons_file, index=False)\n","\n","print(f\"Datasets generated and saved:\\n- {output_so2tons_file}\\n- {output_noxtons_file}\\n- {output_cotons_file}\")\n"]}]}